{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from itertools import product\n",
    "from skimage import measure\n",
    "from math import sqrt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpm(\n",
    "    ground_truth: str, prediction: str, \n",
    "    size_threshold: int, scale: float, \n",
    "    weight_d: float, weight_s: float, weight_a: float):\n",
    "    '''\n",
    "    Returns the discrete protein metric (DPM) similarity score of two focal adhesion (FA) images.\n",
    "    \n",
    "            Parameters:\n",
    "                    ground_truth: A string of the path to image containing membrane and ground truth FA\n",
    "                    prediction: A string of the path to image containing membrane and predicted FA to be compared to ground truth\n",
    "                    size_threshold: An integer value for size threshold; any FAs with an area less than this value are dropped\n",
    "                    scale: A float value for image scale (microns/pixel)\n",
    "                    weight_d: A float value for importance weight to be applied for distribution measurement\n",
    "                    weight_s: A float value for importance weight to be applied for shape/size measurement\n",
    "                    weight_a: A float value for importance weight to be applied for angle measurement\n",
    "            \n",
    "            Returns:\n",
    "                    dpm: A numpy float value for the discrete protein metric score\n",
    "                    d: A numpy float value for the distribution measurement\n",
    "                    s: A numpy float value for the shape/size measurement\n",
    "                    a: A numpy float value for the angle measurement\n",
    "    '''\n",
    "    \n",
    "    def euclidean_distance(row1: slice, row2: slice):\n",
    "        '''\n",
    "        Returns the euclidean distance between two coordinate points.\n",
    "        \n",
    "            Parameters:\n",
    "                    row1: A slice of a list containing a single coordinate point\n",
    "                    row2: A slice of a list containing another coordinate point\n",
    "            \n",
    "            Returns:\n",
    "                    sqrt(distance): A float value for the euclidean distance\n",
    "        '''\n",
    "        distance = 0.0\n",
    "        for i in range(len(row1)-1):\n",
    "            distance += (row1[i] - row2[i])**2\n",
    "        return sqrt(distance)\n",
    "\n",
    "    \n",
    "    def get_neighbors(train: list, test_row: slice, num_neighbors: int):\n",
    "        '''\n",
    "        Returns the n nearest neighbors for one coordinate point.\n",
    "        \n",
    "            Parameters:\n",
    "                    train: A list containing a set of coordinate points\n",
    "                    test_row: A slice of a list containing a single coordinate point\n",
    "                    num_neighbors: An integer value for the n nearest neighbors to be retreived\n",
    "            \n",
    "            Returns:\n",
    "                    neighbors: A list of coordinate points for the n nearest neighbors\n",
    "        '''\n",
    "        distances = list()\n",
    "        for train_row in train:\n",
    "            dist = euclidean_distance(test_row, train_row)\n",
    "            distances.append((train_row, dist))\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        neighbors = list()\n",
    "        for i in range(num_neighbors):\n",
    "            neighbors.append(distances[i][0])\n",
    "        return neighbors\n",
    "    \n",
    "    \n",
    "    def fa_processing(img_path: str, size_threshold: int, scale: float):\n",
    "        '''\n",
    "        Returns numpy arrays for the binary and segmented FA images from the raw FA images.\n",
    "        \n",
    "            Parameters:\n",
    "                    img_path: A string of the path to the image containing raw FA\n",
    "                    size_threshold: An integer value for size threshold; any FAs with an area less than this value are dropped\n",
    "                    scale: A float value for image scale (microns/pixel)\n",
    "            \n",
    "            Returns:\n",
    "                    binary_img: A numpy array of the binary FA image\n",
    "                    seg_img: A numpy array of the segmented FA image\n",
    "        '''\n",
    "        # Read image and extract FA channel into a new empty image\n",
    "        img = cv2.imread(img_path)\n",
    "        res = np.zeros((256, 256, 3))\n",
    "        res[:,:,1] = img[:,:,1]\n",
    "        # Apply a top hat filter with 3x3 rectangular kernel and place filtered image into a new empty image\n",
    "        filterSize =(3, 3)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize)\n",
    "        tophat_img = cv2.morphologyEx(res[:,:,1], cv2.MORPH_TOPHAT, kernel)        \n",
    "        processed_img = res\n",
    "        processed_img[:,:,1] = tophat_img\n",
    "        # Binarize filtered FA image\n",
    "        ret, bw_img = cv2.threshold(processed_img,10,255,cv2.THRESH_BINARY)\n",
    "        gray = rgb2gray(bw_img)\n",
    "        gray = gray * 255\n",
    "        gray = gray.astype(np.uint8)\n",
    "        ret, out_l = cv2.threshold(gray,10,255,cv2.THRESH_BINARY)\n",
    "        # Find the contours of each FA\n",
    "        contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        binary_img = np.zeros((256,256))\n",
    "        # Iterate through each contour\n",
    "        for cntr in contours:\n",
    "            # Use bouding rectangle to find width and height of each FA to calculate area\n",
    "            x,y,w,h = cv2.boundingRect(cntr)\n",
    "            w = w*scale\n",
    "            h = h*scale\n",
    "            area = w*h\n",
    "            # Write FAs that have an area equal or greater than the threshold into a new empty image\n",
    "            if area >= size_threshold:\n",
    "                cv2.drawContours(binary_img, [cntr], 0, (255, 0, 0), -1)\n",
    "        # Apply laplacian operator to binary FA image to obtain segmented FA image\n",
    "        kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "        seg_img = ndimage.convolve(binary_img, kernel_laplace, mode='constant')\n",
    "        seg_img = seg_img * 255\n",
    "        ret, seg_img = cv2.threshold(seg_img,10,255,cv2.THRESH_BINARY)\n",
    "        return binary_img, seg_img\n",
    "    \n",
    "    \n",
    "    def membrane_processing(img_path: str):\n",
    "        '''\n",
    "        Returns numpy array for the segmented membrane image from the raw membrane image.\n",
    "        \n",
    "            Parameters:\n",
    "                    img_path: A string of the path to the image containing raw membrane\n",
    "            \n",
    "            Returns:\n",
    "                    seg_img: A numpy array of the segmented membrane image\n",
    "        '''\n",
    "        # Read image and extract membrane channel to binarize\n",
    "        membrane = cv2.imread(img_path)\n",
    "        ret, bw_img = cv2.threshold(membrane[:,:,2],10,255,cv2.THRESH_BINARY)\n",
    "        # Place binary membrane channel into a new empty image\n",
    "        res = np.zeros((256, 256, 3))\n",
    "        res[:,:,2] = bw_img\n",
    "        gray = rgb2gray(res)\n",
    "        # Apply laplacian operator to binary membrane image to obtain segmented membrane image\n",
    "        kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "        out_l = ndimage.convolve(gray, kernel_laplace, mode='constant')\n",
    "        out_l = out_l * 255\n",
    "        ret, seg_img = cv2.threshold(out_l,10,255,cv2.THRESH_BINARY)\n",
    "        return seg_img\n",
    "    \n",
    "    \n",
    "    # Calculation of distribution (d) measurement\n",
    "    \n",
    "    # Apply membrane processing function to raw ground truth image\n",
    "    membrane = membrane_processing(ground_truth)\n",
    "    # Obtain x-y coordinates for membrane outline from segmented membrane image\n",
    "    pixels = membrane.reshape(-1)\n",
    "    xs = range(membrane.shape[0])\n",
    "    ys = range(membrane.shape[1])\n",
    "    indices = np.array(list(product(xs, ys)))\n",
    "    index = pd.Series(pixels, name=\"pixels\")\n",
    "    df = pd.DataFrame({\n",
    "        \"xmem\" : indices[:, 0],\n",
    "        \"ymem\" : indices[:, 1]\n",
    "    }, index=index)\n",
    "    df = df[df.index != 0]\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['pixels'])\n",
    "    x_values = df['xmem'].values\n",
    "    x_arr = np.reshape(x_values, (-1, 1))\n",
    "    y_values = df['ymem'].values\n",
    "    y_arr = np.reshape(y_values, (-1, 1))\n",
    "    # Obtain minimum and maximum x and y values\n",
    "    min_x = min(x_values)\n",
    "    max_x = max(x_values)\n",
    "    min_y = min(y_values)\n",
    "    max_y = max(y_values)\n",
    "    coordinates = np.hstack((x_arr, y_arr))\n",
    "    # Extract bounds for membrane outline into a list\n",
    "    coord_bound = []\n",
    "    for x in range(min_x, max_x):\n",
    "        new_coord = []\n",
    "        for i in range(len(coordinates)):\n",
    "            if coordinates[i][0] == x:\n",
    "                new_coord.append(coordinates[i][1])\n",
    "        y_min = min(new_coord)\n",
    "        y_max = max(new_coord)\n",
    "        coord_bound.append([x, y_min, y_max])\n",
    "\n",
    "    # Apply fa processing function to raw ground truth image using size threshold and scale defined in dpm function\n",
    "    # and use segmented FA image returned\n",
    "    fa_truth = fa_processing(ground_truth, size_threshold, scale)[1]\n",
    "    # Extract x-y coordinates for centroid of each ground truth FA site into a list\n",
    "    ret,thresh = cv2.threshold(fa_truth,20,255,cv2.THRESH_BINARY_INV)\n",
    "    labels= measure.label(thresh, background=0)\n",
    "    bg_label = labels[0,0] \n",
    "    labels[labels==bg_label] = 0\n",
    "    props = measure.regionprops(labels)\n",
    "    centroids = np.zeros(shape=(len(np.unique(labels)) - 1,2))\n",
    "    for i,prop in enumerate(props):\n",
    "        my_centroid = prop.centroid\n",
    "        centr = [0, 0]\n",
    "        centr[0] = my_centroid[0]\n",
    "        centr[1] = my_centroid[1]\n",
    "        centroids[i,:]= centr\n",
    "    \n",
    "    # Train a k-means clustering algorithm with 5 clusters to ground truth centroid coordinate data\n",
    "    kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42).fit(centroids)\n",
    "\n",
    "    # Apply fa processing function to raw prediction image using size threshold and scale defined in dpm function\n",
    "    # and use segmented FA image returned\n",
    "    fa_pred = fa_processing(prediction, size_threshold, scale)[1]\n",
    "    # Extract x-y coordinates for centroid of each predicted FA site into a list\n",
    "    ret,thresh = cv2.threshold(fa_pred,20,255,cv2.THRESH_BINARY_INV)\n",
    "    labels= measure.label(thresh, background=0)\n",
    "    bg_label = labels[0,0] \n",
    "    labels[labels==bg_label] = 0\n",
    "    props = measure.regionprops(labels)\n",
    "    centroids2 = np.zeros(shape=(len(np.unique(labels)) - 1,2))\n",
    "    for i,prop in enumerate(props):\n",
    "        my_centroid = prop.centroid\n",
    "        centr = [0, 0]\n",
    "        centr[0] = my_centroid[0]\n",
    "        centr[1] = my_centroid[1]\n",
    "        centroids2[i,:]= centr\n",
    "    # Iterate through all predicted FA centroids and only keep centroids that are inside of membrane outline in a new list\n",
    "    centroids_pred = []\n",
    "    for i in range(len(centroids2)):\n",
    "        for j in range(len(coord_bound)):\n",
    "            if int(centroids2[i][0]) == coord_bound[j][0] and coord_bound[j][1] <= int(centroids2[i][1]) <= coord_bound[j][2]:\n",
    "                centroids_pred.append([centroids2[i][0], centroids2[i][1]])\n",
    "    # Calculate number of dropped FAs and use as penalizing factor\n",
    "    dropped_number = len(centroids2) - len(centroids_pred)\n",
    "    if len(centroids2) > 0:\n",
    "        factor = 1 - (dropped_number/len(centroids2))\n",
    "        # Use trained k-means clustering algorithm to predict to which cluster each predicted FA belongs to\n",
    "        pred_clusters = kmeans.predict(centroids_pred)\n",
    "        # Count number of predicted FAs on each cluster\n",
    "        unique_pred, counts_pred = np.unique(pred_clusters, return_counts=True)\n",
    "        # Count number of ground truth FAs on each cluster\n",
    "        truth_clusters = kmeans.labels_\n",
    "        unique_truth, counts_truth = np.unique(truth_clusters, return_counts=True)\n",
    "        # If a cluster has zero FAs, add zero to the counts list\n",
    "        clusters = []\n",
    "        if len(counts_truth) != len(counts_pred):\n",
    "            for j in range(len(counts_truth)-len(counts_pred)):\n",
    "                counts_pred = np.append(counts_pred, 0)\n",
    "        # Calculate the ratio of predicted FAs to ground truth FAs on each cluster\n",
    "        for i in range(len(counts_truth)):\n",
    "            cluster_ind = (min(counts_truth[i], counts_pred[i]))/(max(counts_truth[i], counts_pred[i]))\n",
    "            clusters.append(cluster_ind)\n",
    "        # Calculate d measurement by taking average of ratios for each cluster and multiply by penalizing factor\n",
    "        d = factor*(statistics.mean(clusters))\n",
    "    elif len(centroids2) == 0 and len(centroids) == 0:\n",
    "        d = 1\n",
    "    else:\n",
    "        d = 0\n",
    "    \n",
    "    # Calculation of shape/size (s) and angle (a) measurement\n",
    "    \n",
    "    # Apply fa processing function to raw prediction image using size threshold and scale defined in dpm function\n",
    "    # and use binary FA image returned\n",
    "    segmented_fa = fa_processing(prediction, size_threshold, scale)[0]\n",
    "    segmented_fa_gray = rgb2gray(segmented_fa)\n",
    "    gray = segmented_fa_gray*255\n",
    "    gray = gray.astype(np.uint8)\n",
    "    # Find contours for each predicted FA site\n",
    "    ret, out_l = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "    contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    pred_img = np.zeros((256,256))\n",
    "    rect_coord = []\n",
    "    rect_dim = []\n",
    "    rect_angle = []\n",
    "    # Iterate through all predicted FA sites\n",
    "    for cntr in contours:\n",
    "        # Use bouding rectangle to obtain dimensions and coordinates of each FA site\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        rect_coord.append([x,y])\n",
    "        rect_dim.append([w,h])\n",
    "        # Draw rectangles in a new image\n",
    "        cv2.rectangle(pred_img, (x, y), (x+w, y+h), (255, 0, 0), -1)\n",
    "        # Use minimum area rectangle to obtain angle of orientation of each FA site\n",
    "        center, dim, angle = cv2.minAreaRect(cntr)\n",
    "        rect_angle.append(angle)\n",
    "    \n",
    "    # Repeat same procedure as above to obtain dimensions, coordinates and angle of each ground truth FA site\n",
    "    segmented_fa_truth = fa_processing(ground_truth, size_threshold, scale)[0]\n",
    "    segmented_fa_truth_gray = rgb2gray(segmented_fa_truth)\n",
    "    gray = segmented_fa_truth_gray*255\n",
    "    gray = gray.astype(np.uint8)\n",
    "    ret, out_l = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n",
    "    contours, hier = cv2.findContours(out_l, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_img = np.zeros((256,256))\n",
    "    rect_coord_truth = []\n",
    "    rect_dim_truth = []\n",
    "    rect_angle_truth = []\n",
    "    for cntr in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        rect_coord_truth.append([x,y])\n",
    "        rect_dim_truth.append([w,h])\n",
    "        cv2.rectangle(new_img, (x, y), (x+w, y+h), (255, 0, 0), -1)\n",
    "        center, dim, angle = cv2.minAreaRect(cntr)\n",
    "        rect_angle_truth.append(angle)\n",
    "    \n",
    "    # Create new image to match location of FA sites in ground truth and prediction\n",
    "    ground_truth_centered_img = np.zeros((256,256))\n",
    "    angle_scores = []\n",
    "    # Iterate through all predicted FA sites\n",
    "    for i in range(len(rect_coord)):\n",
    "        # Obtain centroid coordinates for FA site\n",
    "        x_center = rect_coord[i][0] + rect_dim[i][0]//2\n",
    "        y_center = rect_coord[i][1] + rect_dim[i][1]//2\n",
    "        # Obtain nearest neighbor in the ground truth FA sites to the predicted FA site\n",
    "        neighbors = get_neighbors(rect_coord_truth, rect_coord[i], 1)\n",
    "        for neighbor in neighbors:\n",
    "            # Extract nearest neighbor position in the ground truth FA sites list\n",
    "            for j in range(len(rect_coord_truth)):\n",
    "                if neighbor[0] == rect_coord_truth[j][0] and neighbor[1] == rect_coord_truth[j][1]:\n",
    "                    # Obtain dimensions and centroid coordinates for nearest neighbor ground truth FA site\n",
    "                    w = rect_dim_truth[j][0]\n",
    "                    h = rect_dim_truth[j][1]\n",
    "                    x = x_center - w//2\n",
    "                    y = y_center - h//2\n",
    "                    # Write new image with ground truth FA sites located at same position as predicted FA sites\n",
    "                    cv2.rectangle(ground_truth_centered_img, (x, y), (x+w, y+h), (255, 0, 0), -1)\n",
    "                    # Obtain angle score by normalizing angle values to a range of 0-90 degrees\n",
    "                    if rect_angle[i] > 90:\n",
    "                        angle_pred = 180 - rect_angle[i]\n",
    "                    elif -90 <= rect_angle[i] < 0:\n",
    "                        angle_pred = abs(rect_angle[i])\n",
    "                    elif rect_angle[i] < -90:\n",
    "                        angle_pred = 180 - abs(rect_angle[i])\n",
    "                    else:\n",
    "                        angle_pred = rect_angle[i]\n",
    "                    if rect_angle_truth[j] > 90:\n",
    "                        angle_truth = 180 - rect_angle_truth[j]\n",
    "                    elif -90 <= rect_angle_truth[j] < 0:\n",
    "                        angle_truth = abs(rect_angle_truth[j])\n",
    "                    elif rect_angle_truth[j] < -90:\n",
    "                        angle_truth = 180 - abs(rect_angle_truth[j])\n",
    "                    else:\n",
    "                        angle_truth = rect_angle_truth[j]\n",
    "                    # Calculate deviation between predicted and ground truth FA site angle\n",
    "                    angle_dev = abs(angle_pred - angle_truth)\n",
    "                    angle_ind = 1 - (angle_dev/90)\n",
    "                    angle_scores.append(angle_ind)\n",
    "    \n",
    "    # Compare ground truth centered image to predicted image\n",
    "    y_true = ground_truth_centered_img.flatten()\n",
    "    y_true = y_true/255\n",
    "    y_pred = pred_img.flatten()\n",
    "    y_pred = y_pred/255\n",
    "    # Compute true positives, false negatives, and false positives\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for k in range(len(y_true)):\n",
    "        if y_true[k]==1 and y_pred[k]==1:\n",
    "            tp += 1\n",
    "        elif y_true[k]==1 and y_pred[k]==0:\n",
    "            fn += 1\n",
    "        elif y_true[k]==0 and y_pred[k]==1:\n",
    "            fp += 1\n",
    "    # Calculate precision and recall\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    # Calculate s measurement using F1 score\n",
    "    s = (2*precision*recall)/(precision+recall)\n",
    "    # Calculate a measurement by taking averge of angle scores across all FA sites\n",
    "    a = statistics.mean(angle_scores)\n",
    "\n",
    "    # Calculate dpm score using defined weights and obtained d, s, and a measurements\n",
    "    dpm = (weight_d*d)+(weight_s*s)+(weight_a*a)\n",
    "    \n",
    "    return dpm, d, s, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm(ground_truth='unprocessed_ground_truth.png', \n",
    "    prediction='unprocessed_prediction.png', \n",
    "    size_threshold=1, \n",
    "    scale=0.7, \n",
    "    weight_d=0.33, \n",
    "    weight_s=0.33, \n",
    "    weight_a=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
